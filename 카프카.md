## 카프카 Offset
특정 메세지가 특정 파티션에서 어디에 위치하는지를 나타내는 지표. 
#### 오프셋의 특징
1. 고유성: 각 메세지는 해당 파티션 낸에서 유일한 offset을 가지며, 이는 파티션 내에서 메세지의 순서를 나타낸다.
2. 커밋: 컨슈머가 메세지를 처리한 후, 커밋을 통해 마지막으로 읽은 offset을 저장한다. offset은 컨슈머 그룹의 진행 상태를 추적하는데 사용된다. 컨슈머가 재시작되거나 장애가 발생하면 커밋된 offset을 기준으로 처리 상태를 복원한다.
3. 상태 관리: 여러 컨슈머 그룹이 독립적으로 offset을 관리한다. 동일한 파티션의 메세지를 여러 그룹이 별도로 처리할 수 있다.
4. offset 저장소: 카프카는 내부적으로 `__consumer_offsets`에 오프셋 정보를 저장한다. 이 토픽은 컨슈머 그룹의 오프셋 상태를 유지하며, 컨슈머가 커밋한 오프셋을 기록한다.
5. 복구와 리플레이: 저장된 offset을 통해 메세지를 복구하거나 리플레이 할 수 있다.
#### 오프셋 관리
1. 자동 오프셋 커밋: 카프카가 주기적으로 오프셋을 커밋한다. 메세지 처리 중 오류가 발생하거나 consumer가 비정상 종료되면 일부 메세지가 중복처리 되거나 손실될 수 있다.
   ```
   enable.auto.commit = true
   auto.commit.interval.ms = 커밋 주기
   ```  
2. 수동 오프셋 커밋: 메세지를 성공적으로 커밋한 후 명시적으로 오프셋을 커밋한다. (코드에서 직접 관리)
   ```
   commitSync(): 동기식으로 오프셋을 커밋한다. 커밋이 완료될 때까지 멈춘다.
   commitAync(): 비동기식으로 오프셋을 커밋한다. 커밋 요청을 보내고 응답을 기다리지 않는다. 
   ``` 
3. 오프셋 리셋: 스트림의 처음 위치로 돌아가려고 할 때 사용한다.
   - 콘솔 커멘트로 리셋하기: Kafka의 kafka-consumer-groups.sh 스크립트를 사용
   ```
   kafka-consumer-groups.sh --bootstrap-server -localhost:9002 --group my-group --topic my-topic --reset-offsets --to-earliest --execute
   ```
   - 프로그램 적으로 리셋하기: seekToBeginning() 또는 seekToEnd()
   ```
   consumer.seekToBeginning(consumer.assignment());
   consumer.seekToEnd(consumer.assignment());
   ```
4. 커스텀 오프셋 관리
   - 서비스에서 직접 오프셋을 수동으로 조정하거나, 외부 데이터베이스에 오프셋 정보를 저장하고 관리할 수 있다.
   - 외부 데이터베이스의 오프셋 정보를 읽어와 직접 consumer에 오프셋을 지정한다. (seek 메소드 사용)
## 카프카 파티션 
대량 데이터를 효율적으로 처리하고, 저장하기 위해 로그를 여러개의 파티션으로 나누다. 각각의 파티션은 로그의 순서가 보장된다. 
### 파티션의 특징 
1. 데이터 분산: 파티션을 사용하면, 메세지를 여러 서버에 분산 저장할 수 있다. 데이터 병목 현상을 줄일 수 있다.
2. 병렬 처리: 각 파티션은 독립적으로 읽고 쓴다. 카프카 클러스터의 여러 브로커에서 동시에 데이터 처리가 가능해진다.
3. 순서 보장: 같은 파티션에 기록된 메세지는 삽입된 순서대로 유지된다.
4. 내결함성: 파티션은 데이터 복제를 통해 내결함성을 보존한다. 각 파티션은 하나 이상의 복제본을 가지기 때문에 브로커 중 하나가 실패하더라도 데이터가 손실되지 않는다.
5. 스케일링: 파티션 수를 조절해 클러스터의 성능과 용량을 조절할 수 있다.
### 파티션 추가하기
1. 명령어로 파티션 추가하기
   ```
   kafka-topics.sh --bootstrap-server <BROKER_LIST> --alter --topic <TOPIC_NAME> --partitions <NEW_PARTITION_COUNT>
   ```
2. 추가된 파티션 확인하기
   ```
   kafka-topics.sh --bootstrap-server <BROKER_LIST> --describe --topic <TOPIC_NAME>
   ```    
### 파티션 줄이기 
카프카에서 파티션을 줄이는 것은 직접적으로 지원되지 않는다. 파티션을 줄이려면 새로운 토픽을 생성해야 한다. 
1. 새로운 토픽 만들기
2. 데이터를 복사하기
3. 기존 토픽 삭제하기
4. 새로운 토픽으로 consumer를 변경하기

## 카프카 리플리케이션과 ISR
### 리플리케이션 (복제)
Kafka의 리플리케이션은 메세지를 파티션 단위로 저장하고, 파티션의 데이터를 여러 브로커에 복제하여 시스템의 내결함성을 높인다. 
1. 파티션 복제본
      - 각 파티션은 하나 이상의 복제본을 가진다. 주로 브로커 간에 분산되어 저장된다. 
2. 리플리케이션 팩터 
      - 각 파티션의 복제본 수
3. 리더와 팔로워 
      - 파티션에는 하나의 Leader와 Follower가 있다. 리더는 읽기와 쓰기 요청을 처리하고, 팔로워는 리더를 복제한다. 
### ISR (In-Sync Replicas)
현재 리더와 동일한 데이터 상태를 유지하고 있는 복제본 목록이다. 이 목록에 있는 복제본만이 리더에 장애가 났을 때 새로운 리더로 승격될 수 있다. (데이터 유실 방지. 일관성 유지)

## 카프카 커넥터
외부 시스템 간의 데이터 전송을 자동화하고 간소화하기 위한 도구.
데이터 스트림을 source와 sink 시스템 간에 쉽게 연결할 수 있게 한다. 
### 주요 기능 
1. 소스 커넥터: 외부 시스템(예: 데이터베이스, 파일 시스템)에서 카프카 토픽을 읽는다.
2. 싱크 커넥터: 카프카 토픽에서 데이터를 읽어 외부 시스템이 저장한다. 
3. 구성 및 확장성: JSON 또는 프로퍼티 파일을 통해 쉽게 구성할 수 있고, 여러 커넥터를 병렬로 실행해 데이터 파이프라인을 확장할 수 있다.
4. 내장된 데이터 변환: 데이터를 전송하는 과정에서 변환할 수 있는 기능을 제공한다. 데이터 형식을 변환하거나 피드를 추가/제거할 수 있다.
5. 관리 및 모니터링: 커넥터의 상태를 모니터링하고 관리할 수 있는 API와 UI를 제공한다. 이를 통해 데이터 파이프라인의 건강상태와 성능을 확인할 수 있다.
### 커넥터 구현 
1. 소스 커넥터 구현하기
- 커텍터의 구성 및 관리 역할을 하는 객체.
- config: 소스 시스템에 대한 정보, 커넥터 인스턴스를 설정한다.
- taskConfig: 데이터를 추출할 작업Task의 단위를 정의하고, 필요한만큼 SourceTask의 인스턴스를 생성하고 관리한다.
```java
public class MySourceConnector extends SourceConnector {
   @Override
   public void start(Map<String, String> props) {
   }
   @Override
   public Class<? extends Task> taskClass() {
   }
   @Override
   public List<Map<String, String>> taskConfigs(int maxTasks) {}
   @Override
   public void stop() {}
   @Override
    public ConfigDef config() {
        return new ConfigDef().define("my.config", Type.STRING, "default", Importance.HIGH, "Description");
    }
    
    @Override
    public String version() {
        return "1.0";
    }
}
```
2. 소스 테스크 구현하기 
- 실제 데이터 추출 작업을 담당하는 객체. poll로 데이터를 추출하고, SourceRecord로 반환한다. 카프카 커넥트는 이 SourceRecord를 카프카 토픽으로 전송한다. 
```java
public class MySourceTask extends SourceTask {
    @Override
    public void start(Map<String, String> props) {
        // 태스크 초기화
    }
    
    @Override
    public List<SourceRecord> poll() throws InterruptedException {
        // 데이터 추출 및 반환
    }
    
    @Override
    public void stop() {
        // 태스크 종료 작업
    }
    
    @Override
    public String version() {
        return "1.0";
    }
}
```
3. 커넥터 배포
- 커넥터 코드를 JAR 파일로 패키징하고, 이를 카프카 클러스터에 배포한다. 배포 후 카프카 커넥트 클러스터의 plugins.path 설정을 통해 새 커넥터가 로드되게 한다. 
4. 커넥터 설정 
- 커넥터 설정 파일을 작성하여 커넥터를 설정한다. my-source-connector.properties
```
name=my-source-connector
connector.class=com.example.MySourceConnector
tasks.max=1
my.config=some_value
```

   
